{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d2e9a9",
   "metadata": {},
   "source": [
    "# TTT4185 Machine learning for Speech technology\n",
    "\n",
    "## Computer assignment 2: Classification using the Bayes Decision Rule and Support Vector Machines\n",
    "\n",
    "This assignment assumes that the student has knowledge about the Bayes Decision Rule, maximum likelihood estimation and support vector machines.\n",
    "\n",
    "In this assignment we will use `scikit-learn` (http://scikit-learn.org/stable/), which is a powerful and very popular Python toolkit for data analysis and machine learning, and `pandas` (https://pandas.pydata.org), which implements the all-powerful `DataFrame`.\n",
    "\n",
    "We will also be using a small database of phonemes, where each phoneme is represented by the four first formant positions (\"F1\"-\"F4\") and their corresponding bandwidths (\"B1\"-\"B4\"). All numbers are in kHz. In addition, the speaker ID and the gender of the speaker are given for each phoneme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f5aea",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "In this problem we will use the Bayes decision rule to classify vowels based on their formants. The formants have been extracted from the open database `VTR Formants database` (http://www.seas.ucla.edu/spapl/VTRFormants.html) created by Microsoft and UCLA.\n",
    "\n",
    "(a) Download the files `Train.csv` and `Test.csv` from Blackboard, and load them into a `pandas` dataframe using the command `pd.read_csv`. Using the training data, create a single scatter plot of \"F1\" vs \"F2\" for the three vowels\n",
    "- \"ae\" as in \"bat\"\n",
    "- \"ey\" as in \"bait\"\n",
    "- \"ux\" as in \"boot\"\n",
    "\n",
    "Just eyeing the plots, discuss which classes will be hardest to classify correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "# Load data\n",
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "\n",
    "# Extract vowels\n",
    "aes = train[train[\"Phoneme\"] == 'ae']\n",
    "eys = train[train[\"Phoneme\"] == 'ey']\n",
    "uxs = train[train[\"Phoneme\"] == 'ux']\n",
    "\n",
    "# Plotting here\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(aes[\"F1\"].values, aes[\"F2\"].values, color='red', label='ae')\n",
    "plt.scatter(eys[\"F1\"].values, eys[\"F2\"].values, color='blue', label='ey')\n",
    "plt.scatter(uxs[\"F1\"].values, uxs[\"F2\"].values, color='green', label='ux')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d114462a",
   "metadata": {},
   "source": [
    "'Ey' vowel (blue) looks the most difficult to classify according to the plot. Its values are overlayed with 'ae' and 'ux' values on F1 and F2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9607a4",
   "metadata": {},
   "source": [
    "(b) Use the Bayes Decision Rule to create a classifier for the phonemes 'ae', 'ey' and 'ux' under the following constraints:\n",
    "- The feature vector $x$ contains the first two formants, \"F1\" and \"F2\".\n",
    "- The distribution of $x$ given a phoneme $c$, $P(x|c)$, is Gaussian.\n",
    "- Use the maximum likelihood estimator to estimate the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63684fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "X_columns = ['SpeakerID', 'F1', 'F2']\n",
    "X_aes, X_eys, X_uxs = aes[X_columns], eys[X_columns], uxs[X_columns]\n",
    "X_eg = {'ae': X_aes, 'ey': X_eys, 'ux': X_uxs}\n",
    "\n",
    "class BayesClassificator:\n",
    "    def __init__(self, X = X_eg, vowels = ['ae', 'ey', 'ux'], features = ['F1', 'F2'], cov_mode: str = 'cov'):\n",
    "        self.vowels = vowels\n",
    "        self.features = features\n",
    "        X_t = { t: X[t][self.features] for t in self.vowels }\n",
    "        \n",
    "        self.mean_ = { t: X_t[t].mean() for t in self.vowels }\n",
    "        self.cov_ = { t: X_t[t].cov() for t in self.vowels } if cov_mode == 'cov' else { t: np.diag(X_t[t].cov()) for t in self.vowels } if cov_mode == 'answer_g' else Exception(\"Not Implemented\")\n",
    "\n",
    "        len_Xs = 0\n",
    "        for x in X_t.values(): len_Xs += len(x) \n",
    "        len_Xs = len(features)\n",
    "        self.prior_ = { t: len(X_t[t]) / len_Xs for t in self.vowels }\n",
    "    \n",
    "    def likelihood(self, x):\n",
    "        return { t: scipy.stats.multivariate_normal.pdf(x, mean=self.mean_[t], cov=self.cov_[t]) for t in self.vowels }\n",
    "    \n",
    "    def posterior(self, x):\n",
    "        likelihood_ = self.likelihood(x)\n",
    "        evidence = self.evidence(x)\n",
    "        return { t: float(likelihood_[t] * self.prior_[t] / evidence) for t in self.vowels}\n",
    "\n",
    "    def evidence(self, x):\n",
    "        likelihood_ = self.likelihood(x)\n",
    "        return sum(likelihood_[t] * self.prior_[t] for t in self.vowels)\n",
    "\n",
    "    def predict(self, x):\n",
    "        posterior_ = self.posterior(x)\n",
    "        prediction = self.vowels[0]\n",
    "        for t in self.vowels:\n",
    "            if posterior_[t] > posterior_[prediction]: prediction = t\n",
    "        return prediction\n",
    "        \n",
    "    def predict_whole_frame(self, X, target):\n",
    "        error = 0\n",
    "        \n",
    "        for x in np.array(X[self.features]):\n",
    "            if self.predict(x) != target: error += 1\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {'ae': X_aes, 'ey': X_eys, 'ux': X_uxs}\n",
    "vowels = ['ae', 'ey', 'ux']\n",
    "bc = BayesClassificator()\n",
    "for k, x in X.items():\n",
    "    print(f\"success for {k} vowel:\", 1 - bc.predict_whole_frame(X=x, target=k) / len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f62938",
   "metadata": {},
   "source": [
    "(c) To visualize the classes models and the classifier created in (b), plot the contours for each Gaussian distribution in the model, that is the class conditional likelihoods $P(x|c)$, by using the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66263f9f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def plotGaussian(mean, cov, color, ax):\n",
    "    \"\"\" \n",
    "        Creates a contour plot for a bi-variate normal distribution\n",
    "        \n",
    "        mean: numpy array 2x1 with mean vector\n",
    "        cov: numpy array 2x2 with covarince matrix\n",
    "        color: name of color for the plot (see https://matplotlib.org/stable/gallery/color/named_colors.html)\n",
    "        ax: axis handle where the plot is drawn (can for example be returned by plt.gca() or plt.subplots())\n",
    "    \"\"\"\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    x, y = np.mgrid[xlim[0]:xlim[1]:(xlim[1]-xlim[0])/500.0, ylim[0]:ylim[1]:(ylim[1]-ylim[0])/500.0]\n",
    "    xy = np.dstack((x, y))\n",
    "    mvn = scipy.stats.multivariate_normal(mean, cov)\n",
    "    lik = mvn.pdf(xy)\n",
    "    ax.contour(x,y,lik,colors=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52cff6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "vowels = ['ae', 'ey', 'ux']\n",
    "colors = { vowels[k]: ['red', 'blue', 'green'][k] for k in range(len(vowels))}\n",
    "X_ = X_eg\n",
    "\n",
    "minF1, maxF1 = pd.concat([X_[t]['F1'] for t in vowels]).min(), pd.concat([X_[t]['F1'] for t in vowels]).max()\n",
    "minF2, maxF2 = pd.concat([X_[t]['F2'] for t in vowels]).min(), pd.concat([X_[t]['F2'] for t in vowels]).max()\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.set_xlim(minF1, maxF1), ax.set_ylim(minF2, maxF2)\n",
    "[plotGaussian(X_[t][['F1','F2']].mean(), X_[t][['F1','F2']].cov(), color=colors[t], ax=ax) for t in vowels]\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad40f63e",
   "metadata": {},
   "source": [
    "*Try:* Plot the decision regions for the Bayesian classifier. Tips: Calculate the posterior for each class, use the `numpy.argmax` function to get the decision regions, and `matplotlib.pyplot.contourf` to plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4bf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {'ae': X_aes[['F1', 'F2']], 'ey': X_eys[['F1', 'F2']], 'ux': X_uxs[['F1', 'F2']]}\n",
    "bc = BayesClassificator()\n",
    "\n",
    "posterior_ = {}\n",
    "for t in bc.vowels:\n",
    "    for x in np.array(X[t]):\n",
    "        likelihood_ = bc.likelihood(x)\n",
    "        evidence = bc.evidence(x)\n",
    "        posterior_[tuple(x)] = { t: likelihood_[t] * bc.prior_[t] / evidence for t in bc.vowels }\n",
    "posterior_\n",
    "\n",
    "\n",
    "argmax = { t: np.array(X[t])[np.argmax([posterior_[tuple(x)][t] for x in np.array(X[t])])] for t in bc.vowels}\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.set_xlim(minF1, maxF1), ax.set_ylim(minF2, maxF2)\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "x, y = np.mgrid[xlim[0]:xlim[1]:(xlim[1]-xlim[0])/500.0, ylim[0]:ylim[1]:(ylim[1]-ylim[0])/500.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fdf539",
   "metadata": {},
   "source": [
    "(d) Test your classifier on the 'ae', 'ey' and 'ux' phonemes from the test set and present your results in a _confusion matrix_, that is, a table where you see how many times 'ae' was correctly classified, how many times it was wrongly classified as 'ey' and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "bc = BayesClassificator()\n",
    "\n",
    "X_test = { t: np.array(test[test[\"Phoneme\"] == t][['F1', 'F2']]) for t in bc.vowels }\n",
    "\n",
    "\n",
    "prediction = []\n",
    "actual = []\n",
    "for t in bc.vowels:\n",
    "    for x in X_test[t]:\n",
    "        prediction.append(bc.predict(x))\n",
    "        actual.append(t)\n",
    "\n",
    "print(\"Confusion matrix of the test set:\\n\", confusion_matrix(actual, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a694d",
   "metadata": {},
   "source": [
    "(e) Extend your classifier to include the features \"F1\"-\"F4\" and compare the results with those in (d). Finally use all available information \"F1\"-\"F4\" and \"B1-B4\". How does the performance of this classifier compare with the simpler classifiers using fewer features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['F1', 'F2', 'F3', 'F4']\n",
    "vowels = ['ae', 'ey', 'ux']\n",
    "X_train = { t: train[train[\"Phoneme\"] == t][features] for t in vowels }\n",
    "\n",
    "bcF1_F4 = BayesClassificator(X=X_train, features=features)\n",
    "X_test = { t: test[test[\"Phoneme\"] == t][features] for t in vowels }\n",
    "\n",
    "print(\"Model with features F1 - F4 included:\\n\")\n",
    "print('Results on training:')\n",
    "for k, x in X_train.items():\n",
    "    print(f\"success for {k} vowel:\", 1 - bcF1_F4.predict_whole_frame(X=x, target=k) / len(x))\n",
    "print('\\nResults on testing:')\n",
    "for k, x in X_test.items():\n",
    "    print(f\"success for {k} vowel:\", 1 - bcF1_F4.predict_whole_frame(X=x, target=k) / len(x))\n",
    "\n",
    "prediction = []\n",
    "actual = []\n",
    "for t in vowels:\n",
    "    for x in np.array(X_test[t]):\n",
    "        prediction.append(bcF1_F4.predict(x))\n",
    "        actual.append(t)\n",
    "\n",
    "print(\"\\nConfusion matrix of the test set:\\n\", confusion_matrix(actual, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['F1', 'F2', 'F3', 'F4', 'B1', 'B2', 'B3', 'B4']\n",
    "\n",
    "X_train = { t: train[train[\"Phoneme\"] == t][features] for t in vowels }\n",
    "\n",
    "bcF1_B4 = BayesClassificator(X=X_train, features=features)\n",
    "X_test = { t: test[test[\"Phoneme\"] == t][features] for t in vowels }\n",
    "\n",
    "print(\"Model with features F1 - F4 - B1 - B4 included:\\n\")\n",
    "print('Results on training:')\n",
    "for k, x in X_train.items():\n",
    "    print(f\"success for {k} vowel:\", 1 - bcF1_B4.predict_whole_frame(X=x, target=k) / len(x))\n",
    "print('\\nResults on testing:')\n",
    "for k, x in X_test.items():\n",
    "    print(f\"success for {k} vowel:\", 1 - bcF1_B4.predict_whole_frame(X=x, target=k) / len(x))\n",
    "\n",
    "predictions = []\n",
    "actual = []\n",
    "score = 0\n",
    "for t in bcF1_B4.vowels:\n",
    "    for x in np.array(X_test[t]):\n",
    "        prediction = bcF1_B4.predict(x)\n",
    "        if prediction == t: score += 1\n",
    "        predictions.append(prediction)\n",
    "        actual.append(t)\n",
    "\n",
    "print(\"\\nScore:\", score / len(predictions))\n",
    "print(\"\\nConfusion matrix of the test set:\\n\", confusion_matrix(actual, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c64b62",
   "metadata": {},
   "source": [
    "(f) We want to make the model slightly more powerful by modeling the feature vector conditional on both the vowel and gender of speaker, that is $P(x|g,c)$, where $g$ is the gender of the speaker and $c$ is the phoneme label. Show how these models can be used for phoneme classification using marginalization over the gender.\n",
    "\n",
    "Assume that $P(x|g,c)$ is a multivariate Gaussian and compute the maximum likelihood estimates for the models. Compare the result on the test set with the results in (e)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bayes_classificator_with_gender(features = ['F1', 'F2'], cov_mode = 'cov'):\n",
    "    vowels = ['ae', 'ey', 'ux']\n",
    "    genders = ['F', 'M']\n",
    "    X_train = { g: {} for g in genders}\n",
    "    for t in vowels:\n",
    "        for g in genders:\n",
    "            X_train[g][t] = train[(train[\"Phoneme\"] == t) & (train[\"Gender\"] == g)][features]\n",
    "\n",
    "    bc_features = { g: BayesClassificator(X=X_train[g], features=features, vowels=vowels, cov_mode=cov_mode) for g in genders }\n",
    "\n",
    "    X_test = { g: {} for g in genders }\n",
    "    for t in vowels:\n",
    "        for g in ['F', 'M']:\n",
    "            X_test[g][t] = test[(test[\"Phoneme\"] == t) & (test[\"Gender\"] == g)][features]\n",
    "    \n",
    "    print(f\"Model with features {features[0]} - {features[len(features) - 1]} knowing the gender:\\n\")\n",
    "    \n",
    "    train_card_ = { g:{ t: 0 for t in vowels } for g in genders }\n",
    "    test_card_ = { g:{ t: 0 for t in vowels } for g in genders }\n",
    "\n",
    "    for t in vowels:\n",
    "        for g in genders:\n",
    "            train_card_[g][t] += len(X_train[g][t])\n",
    "            test_card_[g][t] += len(X_test[g][t])\n",
    "\n",
    "    scores_train = { g: {} for g in genders }\n",
    "    scores_test = { g: {} for g in genders }\n",
    "    for g in genders: \n",
    "        for k, x in X_train[g].items():\n",
    "            scores_train[g][k] = 1 - bc_features[g].predict_whole_frame(X=x, target=k) / len(x)\n",
    "        for k, x in X_test[g].items():\n",
    "            scores_test[g][k] = 1 - bc_features[g].predict_whole_frame(X=x, target=k) / len(x)\n",
    "    \n",
    "    prediction = []\n",
    "    actual = []\n",
    "    for g in genders:\n",
    "        for t in bc_features[g].vowels:\n",
    "            for x in np.array(X_test[g][t]):\n",
    "                prediction.append(bc_features[g].predict(x))\n",
    "                actual.append(t)\n",
    "\n",
    "    score_train = 0\n",
    "    score_test = 0\n",
    "    total_train = 0\n",
    "    total_test = 0\n",
    "    for t in vowels:\n",
    "        score_train += (scores_train['F'][t] * len(X_train['F'][t]) + scores_train['M'][t] * len(X_train['M'][t])) \n",
    "        score_test += (scores_test['F'][t] * len(X_test['F'][t]) + scores_test['M'][t] * len(X_test['M'][t])) \n",
    "        total_train += (len(X_train['F'][t]) + len(X_train['M'][t]))\n",
    "        total_test += (len(X_test['F'][t]) + len(X_test['M'][t]))\n",
    "        print(f\"Score on phoneme {t} on training: {(scores_train['F'][t] * len(X_train['F'][t]) + scores_train['M'][t] * len(X_train['M'][t])) / (len(X_train['F'][t]) + len(X_train['M'][t])) }\")\n",
    "        print(f\"Score on phoneme {t} on testing: {(scores_test['F'][t] * len(X_test['F'][t]) + scores_test['M'][t] * len(X_test['M'][t])) / (len(X_test['F'][t]) + len(X_test['M'][t])) }\")\n",
    "\n",
    "\n",
    "    print(\"\\nScore on training:\", score_train / total_train)\n",
    "    print(\"Score on testing:\",  score_test / total_test)\n",
    "    print(\"\\nConfusion matrix of the test set:\\n\", confusion_matrix(actual, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bayes_classificator_with_gender(['F1', 'F2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bayes_classificator_with_gender(['F1', 'F2', 'F3', 'F4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bayes_classificator_with_gender(['F1', 'F2', 'F3', 'F4', 'B1', 'B2', 'B3', 'B4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c1d78",
   "metadata": {},
   "source": [
    "(g) When using Gaussian classifiers we often avoid computing the entire covariance matrix, but instead we only use the diagonal of the matrix. Repeat the results in (f) using only diagonal covariance matrices and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20630a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bayes_classificator_with_gender(['F1', 'F2', 'F3', 'F4'], cov_mode='answer_g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bayes_classificator_with_gender(['F1', 'F2', 'F3', 'F4', 'B1', 'B2', 'B3', 'B4'], cov_mode='answer_g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237c6fe",
   "metadata": {},
   "source": [
    "These results are a bit lower than the previous one (except to predict ux on testing). This result is not surprising because we remove a lot of complexity. However this results can be satisfying."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c6c72",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "In this problem we use the support vector machine (SVM) to build classifiers. We use the same dataset as in Problem 1. It is up to you to select which features to use.\n",
    "\n",
    "We use the function `sklearn.svm.SVC` from `scikit-learn` in this problem. First you need to get your data on the format that `SVC` expects, which is a matrix where every row is a feature vector, and a list of integer labels corresponding to each row. We suggest using \"ae\" = 0, \"ey\" = 1 and \"ux\" = 2.\n",
    "\n",
    "An example on how to use the `SVC` is given in http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC. In short, we do the following (for a linear kernel):\n",
    "- Instantiate an SVC object: `cls = SVC(kernel='linear')`\n",
    "- Train the SVM using the feature vector matrix `train_X`, and label vector `train_Y`: `cls.fit(train_X, train_Y)`\n",
    "- Predict labels on the test set `Test_X` using: `cls.predict(Test_X)`\n",
    "\n",
    "You can use or adapt the following functions to visualize the SVM decision regions and support vectors in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def Plot_SVM_decision_regions(clf,data,labels):\n",
    "    '''\n",
    "    This function is for plotting the decision area of SVM\n",
    "    \n",
    "    Args:\n",
    "    - clf: SVM model\n",
    "    - data: Data with two features\n",
    "    - labels: Corresponding labels of the data\n",
    "    '''\n",
    "    phonemes = np.array([\"ae\",\"ey\",\"ux\"])\n",
    "    x_min, x_max = data[:,0].min() - 0.2, data[:,0].max() + 0.2\n",
    "    y_min, y_max = data[:,1].min() - 0.2, data[:,1].max() + 0.2\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.002),np.arange(y_min, y_max, 0.002))\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(phonemes)\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = label_encoder.transform(Z)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    #Plotting\n",
    "    plt.figure(figsize=(10,6))\n",
    "    # sns.scatterplot(data[:,0],data[:,1],hue=labels)\n",
    "    plt.scatter(data[:,0],data[:,1])\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.ocean, alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.title('Decision Area of SVM')\n",
    "    plt.show()\n",
    "\n",
    "def Plot_Support_Vectors(clf,data):\n",
    "    '''\n",
    "    This function is for plotting the support vectors of the SVM model\n",
    "    \n",
    "    Args:\n",
    "    - clf: SVM model\n",
    "    - data: Data with two features\n",
    "    '''\n",
    "    x_min, x_max = data[:,0].min() - 0.2, data[:,0].max() + 0.2\n",
    "    y_min, y_max = data[:,1].min() - 0.2, data[:,1].max() + 0.2\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.002),np.arange(y_min, y_max, 0.002))\n",
    "    label_encoder = LabelEncoder()\n",
    "    phonemes = np.array([\"ae\",\"ey\",\"ux\"])\n",
    "    integer_encoded = label_encoder.fit_transform(phonemes)\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = label_encoder.transform(Z)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    #Plotting\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(clf.support_vectors_[:,0], clf.support_vectors_[:,1], c='k',alpha=0.4,label='support vector')\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.ocean, alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.title('Support Vectors')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10175526",
   "metadata": {},
   "source": [
    "(a) Create a linear SVM with different penalty terms $C=\\{0.1, 1, 10\\}$ and compare with the results in Problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b164f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "C = [ 0.1, 1, 10 ]\n",
    "features = ['F1', 'F2', 'F3', 'F4', 'B1', 'B2', 'B3', 'B4']\n",
    "\n",
    "X_train_linear = []\n",
    "y_train_linear = []\n",
    "X_test_linear = []\n",
    "y_test_linear = []\n",
    "\n",
    "for t in vowels:\n",
    "    for x in np.array(train[(train[\"Phoneme\"] == t)][features]):\n",
    "        X_train_linear.append(x)\n",
    "        y_train_linear.append(t)\n",
    "        \n",
    "    for x in np.array(test[(test[\"Phoneme\"] == t)][features]):\n",
    "        X_test_linear.append(x)\n",
    "        y_test_linear.append(t)\n",
    "\n",
    "clf_linear = {}\n",
    "y_pred_linear = {}\n",
    "score_linear = {}\n",
    "for c in C:\n",
    "    # clf_linear[c] = make_pipeline(StandardScaler(), LinearSVC(dual=\"auto\", random_state=0, tol=1e-6, C=c))\n",
    "    clf_linear[c] = LinearSVC(dual=\"auto\", random_state=0, tol=1e-6, C=c)\n",
    "    clf_linear[c].fit(X_train_linear, y_train_linear)\n",
    "    y_pred_linear[c] = clf_linear[c].predict(X_test_linear)\n",
    "    score_linear[c] = clf_linear[c].score(X_test_linear, y_test_linear)\n",
    "    print(f\"Confusion matrix of linear SVM with penalty term C = {c}:\\n\", confusion_matrix(y_test_linear, y_pred_linear[c]))\n",
    "    print('Score (success / length(y)): ', score_linear[c], end=\"\\n\\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff419e",
   "metadata": {},
   "source": [
    "This results are a bit worst than the results found in problem 1 when knowing features F1 to B4 without knowing the gender (except to predict 'ey'). As a reminder, we get: \n",
    "\n",
    "Score: 0.7121771217712177\n",
    "\n",
    "Confusion matrix of the test set:\n",
    "\n",
    " [[82 23  0]\n",
    "\n",
    " [13 90 11]\n",
    " \n",
    " [ 3 28 21]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1c767",
   "metadata": {},
   "source": [
    "If we take all the features into consideration, the model in problem 1 seams to be better than the linear SVM model (for every penalty coefficient). We get higher scores and the components of the diagonal of the confusion matrix are higher. \n",
    "\n",
    "If we do not look on the gender (as following), we get a similar score than the problem 1 model ($\\approx 0.71$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69945329",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [ 0.1, 1, 10 ]\n",
    "features = ['F1', 'F2', 'F3', 'F4', 'B1', 'B2', 'B3', 'B4']\n",
    "genders = ['F', 'M']\n",
    "\n",
    "X_train_linear = { g: [] for g in genders}\n",
    "y_train_linear = { g: [] for g in genders}\n",
    "X_test_linear = { g: [] for g in genders}\n",
    "y_test_linear = { g: [] for g in genders}\n",
    "\n",
    "\n",
    "for g in genders:\n",
    "    for t in vowels:\n",
    "        for x in np.array(train[(train[\"Phoneme\"] == t)& (train[\"Gender\"] == g)][features]):\n",
    "            X_train_linear[g].append(x)\n",
    "            y_train_linear[g].append(t)\n",
    "            \n",
    "        for x in np.array(test[(test[\"Phoneme\"] == t)& (test[\"Gender\"] == g)][features]):\n",
    "            X_test_linear[g].append(x)\n",
    "            y_test_linear[g].append(t)\n",
    "\n",
    "clf_linear = {g: {} for g in genders}\n",
    "y_pred_linear = {g: {} for g in genders}\n",
    "score_linear = {g: {} for g in genders}\n",
    "for c in C:\n",
    "    print(f\"Penalty term C = {c}:\")\n",
    "    for g in genders:\n",
    "        clf_linear[g][c] = make_pipeline(StandardScaler(), LinearSVC(dual=\"auto\", random_state=0, tol=1e-6, C=c))\n",
    "        # clf_linear[g][c] = LinearSVC(dual=\"auto\", random_state=0, tol=1e-6, C=c)\n",
    "        clf_linear[g][c].fit(X_train_linear[g], y_train_linear[g])\n",
    "        y_pred_linear[g][c] = clf_linear[g][c].predict(X_test_linear[g])\n",
    "        score_linear[g][c] = clf_linear[g][c].score(X_test_linear[g], y_test_linear[g])\n",
    "        print(f\"Confusion matrix of linear SVM knowing gender {g}\\n\", confusion_matrix(y_test_linear[g], y_pred_linear[g][c]))\n",
    "        print(f'Score (success / length(y)), knowing gender {g}: ', score_linear[g][c], end=\"\\n\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f164dc7f",
   "metadata": {},
   "source": [
    "The results are similar to the one in the previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [ 0.1, 1, 10 ]\n",
    "\n",
    "vowel_labels = { vowels[k]: k for k in range(len(vowels)) }\n",
    "vowel_labels = { vowels[k]: vowels[k] for k in range(len(vowels)) }\n",
    "features = ['F1', 'F2']\n",
    "X_train = []\n",
    "y_train = []\n",
    "for t in vowels:\n",
    "    for x in np.array(train[train[\"Phoneme\"] == t][features]):\n",
    "        X_train.append(x)\n",
    "        y_train.append(vowel_labels[t])\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for t in vowels:\n",
    "    for x in np.array(test[test[\"Phoneme\"] == t][features]):\n",
    "        X_test.append(x)\n",
    "        y_test.append(vowel_labels[t])\n",
    "\n",
    "clf_linear_to_plot = {}\n",
    "y_pred = {}\n",
    "score = {}\n",
    "\n",
    "X_train, X_test = np.array(X_train), np.array(X_test)\n",
    "X_train[:, 0] = (X_train[:, 0] - min(X_train[:, 0])) / (max(X_train[:, 0]) - min(X_train[:, 0]))\n",
    "X_train[:, 1] = (X_train[:, 1] - min(X_train[:, 1])) / (max(X_train[:, 1]) - min(X_train[:, 1]))\n",
    "X_test[:, 0] = (X_test[:, 0] - min(X_test[:, 0])) / (max(X_test[:, 0]) - min(X_test[:, 0]))\n",
    "X_test[:, 1] = (X_test[:, 1] - min(X_test[:, 1])) / (max(X_test[:, 1]) - min(X_test[:, 1]))\n",
    "\n",
    "for c in C:\n",
    "    clf_linear_to_plot[c] = SVC(kernel='linear', C=c)\n",
    "    clf_linear_to_plot[c].fit(X_train, y_train)\n",
    "    y_pred[c] = clf_linear_to_plot[c].predict(X_test)\n",
    "    score[c] = clf_linear_to_plot[c].score(X_test, y_test)\n",
    "\n",
    "for c in C:\n",
    "    print(f\"Linear SVM descision region for C={c}:\")\n",
    "    Plot_SVM_decision_regions(clf=clf_linear_to_plot[c], data=X_train, labels=[\"F1\",\"F2\"])\n",
    "    print(f\"Linear SVM support vector for C={c}:\")\n",
    "    Plot_Support_Vectors(clf=clf_linear_to_plot[c], data=X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2d617",
   "metadata": {},
   "source": [
    "(b) Try different kernels ('rbf', 'poly', 'sigmoid') and compare the results. Choose one of the kernels and use different penalty terms $C$. What happens with the performance on the training set when you increase $C$? What happens with the performance on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca74355",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [ 0.1, 1, 10 ]\n",
    "features = ['F1', 'F2', 'F3', 'F4', 'B1', 'B2', 'B3', 'B4']\n",
    "kernels = ['rbf', 'poly', 'sigmoid']\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for t in vowels:\n",
    "    for x in np.array(train[(train[\"Phoneme\"] == t)][features]):\n",
    "        X_train.append(x)\n",
    "        y_train.append(t)\n",
    "        \n",
    "    for x in np.array(test[(test[\"Phoneme\"] == t)][features]):\n",
    "        X_test.append(x)\n",
    "        y_test.append(t)\n",
    "\n",
    "clf = {}\n",
    "y_pred = {}\n",
    "score_train = {}\n",
    "score_test = {}\n",
    "\n",
    "for k in kernels: \n",
    "    clf[k] = {}\n",
    "    y_pred[k] = {}\n",
    "    score_train[k] = {}\n",
    "    score_test[k] = {}\n",
    "    for c in C:\n",
    "        clf[k][c] = make_pipeline(StandardScaler(), SVC(kernel=k, C=c))\n",
    "        clf[k][c].fit(X_train, y_train)\n",
    "        y_pred[k][c] = clf[k][c].predict(X_test)\n",
    "        score_train[k][c] = clf[k][c].score(X_train, y_train)\n",
    "        score_test[k][c] = clf[k][c].score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a02fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train, score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0bcbe",
   "metadata": {},
   "source": [
    "We can see that on training set the score increases with C on both rbf and poly methods. On sigmoid the result is weird, as we can see the score is decreasing.\n",
    "\n",
    "On the testing set we can see the same thing, except for sigmoid again. It decrease between 0.1 and 1 and then in crease from 1 to 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1bbd50",
   "metadata": {},
   "source": [
    "We can see now what happens if we know the gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c83d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [ 0.1, 1, 10 ]\n",
    "features = ['F1', 'F2', 'F3', 'F4', 'B1', 'B2', 'B3', 'B4']\n",
    "kernels = ['rbf', 'poly', 'sigmoid']\n",
    "\n",
    "X_train = { g: [] for g in genders}\n",
    "y_train = { g: [] for g in genders}\n",
    "X_test = { g: [] for g in genders}\n",
    "y_test = { g: [] for g in genders}\n",
    "\n",
    "\n",
    "for g in genders:\n",
    "    for t in vowels:\n",
    "        for x in np.array(train[(train[\"Phoneme\"] == t)& (train[\"Gender\"] == g)][features]):\n",
    "            X_train[g].append(x)\n",
    "            y_train[g].append(t)\n",
    "            \n",
    "        for x in np.array(test[(test[\"Phoneme\"] == t)& (test[\"Gender\"] == g)][features]):\n",
    "            X_test[g].append(x)\n",
    "            y_test[g].append(t)\n",
    "\n",
    "clf = { k: { g: {} for g in genders } for k in kernels }\n",
    "y_pred = { k: { g: {} for g in genders } for k in kernels }\n",
    "score_train = { k: { g: {} for g in genders } for k in kernels }\n",
    "score_test = { k: { g: {} for g in genders } for k in kernels }\n",
    "\n",
    "for k in kernels: \n",
    "    for g in genders:\n",
    "        for c in C:\n",
    "            clf[k][g][c] = make_pipeline(StandardScaler(), SVC(kernel=k, C=c))\n",
    "            clf[k][g][c].fit(X_train[g], y_train[g])\n",
    "            y_pred[k][g][c] = clf[k][g][c].predict(X_test[g])\n",
    "            score_train[k][g][c] = clf[k][g][c].score(X_train[g], y_train[g])\n",
    "            score_test[k][g][c] = clf[k][g][c].score(X_test[g], y_test[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train, score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13314b4b",
   "metadata": {},
   "source": [
    "We can see that the value of the score depends on a lot of parameters. If we know the gender, when C increase, there is two scenarios. The score increases from 0.1 to 10 or it increases from 0.1 to 1 and then decrease between 1 and 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4d094",
   "metadata": {},
   "source": [
    "To see the support vectors considering F1 and F2 on all kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d8a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [ 0.1, 1, 10 ]\n",
    "\n",
    "features = ['F1', 'F2']\n",
    "kernels = ['rbf', 'poly', 'sigmoid']\n",
    "X_train = []\n",
    "y_train = []\n",
    "for t in vowels:\n",
    "    for x in np.array(train[train[\"Phoneme\"] == t][features]):\n",
    "        X_train.append(x)\n",
    "        y_train.append(vowel_labels[t])\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for t in vowels:\n",
    "    for x in np.array(test[test[\"Phoneme\"] == t][features]):\n",
    "        X_test.append(x)\n",
    "        y_test.append(vowel_labels[t])\n",
    "clf = {}\n",
    "y_pred = {}\n",
    "score_train = {}\n",
    "score_test = {}\n",
    "\n",
    "for k in kernels: \n",
    "    clf[k] = {}\n",
    "    y_pred[k] = {}\n",
    "    score_train[k] = {}\n",
    "    score_test[k] = {}\n",
    "    for c in C:\n",
    "        # clf[k][c] = make_pipeline(StandardScaler(), SVC(kernel=k, C=c))\n",
    "        clf[k][c] = SVC(kernel=k, C=c)\n",
    "        clf[k][c].fit(X_train, y_train)\n",
    "        y_pred[k][c] = clf[k][c].predict(X_test)\n",
    "        score_train[k][c] = clf[k][c].score(X_train, y_train)\n",
    "        score_test[k][c] = clf[k][c].score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793cb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in kernels:\n",
    "    Plot_Support_Vectors(clf=clf[k][c], data=np.array(X_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signalp1",
   "language": "python",
   "name": "signalp1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
