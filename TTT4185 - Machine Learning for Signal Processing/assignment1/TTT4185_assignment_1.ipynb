{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student: Arthur Testard\n",
    "## Student id: 105022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTT4185 Machine learning for Speech technology\n",
    "\n",
    "## Computer assigment 1: Speech analysis\n",
    "\n",
    "This assignment assumes that the student has knowledge about short-time spectral estimation, linear prediction modeling and cepstral analysis. You should also know the concept of fundamental frequencies and formants.\n",
    "\n",
    "Useful plotting commands from `matplotlib.pyplot`: `figure`, `plot`, `subplots`, `pcolormesh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "In this problem we will look at a speech signal and do simple spectral analysis on the signal.\n",
    "\n",
    "(a) Download the speech file `stry.wav` from Blackboard and load the file using `scipy.io.wavefile.read`. The speech represents the latter half of the English word \"tapestry\". The phonetic transcription is /s/ /t/ /r/ /iy/.\n",
    "- Plot the signal.\n",
    "- What is characteristic about the sounds /s/, /t/, /r/ and /iy/?\n",
    "- Take a 40 millisecond subset of the vowel /iy/ and plot it.\n",
    "- Find the fundamental frequency $f_0$ of the vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "Fs, data = scipy.io.wavfile.read('stry.wav')\n",
    "print(Fs, len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We first plot the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "duration = len(data) / Fs\n",
    "time = np.linspace(0, duration, len(data))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(time, data, color='b')\n",
    "plt.title('Audio Signal')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data = np.fft.fft(data)\n",
    "freqs = np.fft.fftfreq(len(fft_data), 1 / Fs)\n",
    "\n",
    "magn_fft_data = np.abs(fft_data)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(freqs[:len(fft_data)//2], magn_fft_data[:len(fft_data)//2], color='b')\n",
    "plt.title('FFT of Audio Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is characteristic about the sounds /s/, /t/, /r/ and /iy/?\n",
    "\n",
    "/s/ sound: very dense (high frequency), quite long and big amplitude. The vocal cords don't vibrate during its production.\n",
    "\n",
    "/t/ sound: silence after the first sound, it's produced by completely blocking the airflow at the alveolar ridge and then releasing it abruptly. It can be relate to a Dirac signal.\n",
    "\n",
    "/r/ sound: vowel-like sound\n",
    "\n",
    "/iy/ sound: characterized by a pure vowel quality (low frequency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a 40 millisecond subset of the vowel /iy/ and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, dt = 0.25, 0.04\n",
    "t1 = t0 + dt\n",
    "\n",
    "iy_signal = data[int(t0 * Fs) : int(t1 * Fs)]\n",
    "time = np.linspace(t0, t1, len(iy_signal))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(time, iy_signal, color='b')\n",
    "plt.title('/iy/ signal')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_iy = np.fft.fft(iy_signal)\n",
    "freqs_iy = np.fft.fftfreq(len(fft_iy), 1 / Fs)\n",
    "magn_fft_iy = np.abs(fft_iy)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(freqs_iy[:len(fft_iy) // 8], magn_fft_iy[:len(fft_iy)// 8], color='b')\n",
    "plt.title('FFT of Audio Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the fundamental frequency $f_0$ of the vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "\n",
    "peaks, properties = signal.find_peaks(magn_fft_iy, prominence=1, height=1e5)\n",
    "\n",
    "# The fundamental frequency correspond to the first value \n",
    "# of the list because it corresponds to the first peak where \n",
    "# the magnitude is higher than 100 000\n",
    "\n",
    "amp = properties['prominences'][0] \n",
    "freq_iy_index = peaks[0]\n",
    "\n",
    "print(\"Estimated fundamental frequency (f0):\", freqs_iy[freq_iy_index], \"Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Spectral analysis\n",
    "- Estimate the spectrum of the vowel using an FFT of length 1024. Plot the spectrum expressed in dBs ($20 \\log_{10}(x)$) as a function of frequency.\n",
    "- Multiply the signal by a Hamming window and repeat the last operation.\n",
    "- Explain the difference between the two spectra.\n",
    "- Estimate the fundamental frequency $f_0$ using the spectrum, and compare the result to what you got in 1a)\n",
    "- Roughly estimate the two first formant frequencies.\n",
    "\n",
    "Useful Python functions: `numpy.fft.fft`, `numpy.abs`, `scipy.signal.hamming`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_iy = np.fft.fft(iy_signal, n=1024)\n",
    "\n",
    "freqs_iy = np.fft.fftfreq(len(fft_iy), 1 / Fs)\n",
    "magn_db_iy = 20 * np.emath.log10(np.abs(fft_iy))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(freqs_iy[:len(fft_iy) // 8], magn_db_iy[:len(fft_iy) // 8], color='b')\n",
    "plt.title('Spectrum of /iy/ signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "iy_hamming_signal = iy_signal * signal.hamming(len(iy_signal))\n",
    "\n",
    "fft_iy_hamming = np.fft.fft(iy_hamming_signal, 1024)\n",
    "freqs_iy_hamming = np.fft.fftfreq(len(fft_iy_hamming), 1 / Fs)\n",
    "magn_db_hamming = 20 * np.log10(np.abs(fft_iy_hamming))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(freqs_iy_hamming[:len(fft_iy_hamming)//4], magn_db_hamming[:len(fft_iy_hamming)//4], color='b')\n",
    "plt.plot(freqs_iy_hamming[:len(fft_iy)//4], magn_db_iy[:len(fft_iy)//4], color='r')\n",
    "plt.title('Spectrum of /iy/ signal (red) and spectrum of /iy/ signal by Hamming window (blue)')\n",
    "plt.xlabel('Frequency (Hz)') \n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a Hamming window is applied to the signal before performing the FFT, the signal becomes thinner towards the edges. This thinning reduces the leakage of spectral energy from one frequency component to another. As a result, the spectrum with the Hamming window has narrower peaks and weaker sidelobes than the spectrum without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_hamming, properties_hamming = signal.find_peaks(magn_db_hamming, prominence=1, height=90)\n",
    "\n",
    "print(\"Estimated fundamental frequency (f0):\", freqs_iy_hamming[peaks_hamming[0]], \"Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a fundamental frequency a bit different than the previous one. It can be explain by the spreading of the frequencies made by the hamming window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices = np.argsort(magn_db_hamming[:len(magn_db_hamming) // 2])[::-1][1:]\n",
    "\n",
    "print(f\"First formant frequency: {freqs_iy_hamming[peak_indices[0]]} Hz\")\n",
    "print(f\"Second formant frequency: {freqs_iy_hamming[peak_indices[1]]} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) AR modeling\n",
    "- Compute the coefficients of an AR model (linear prediction coefficients) with order 4, 8, 16 and 50, based on the vowel.\n",
    "- Estimate the spectrum for each of the model orders. Plot the spectrum in dBs as a function of frequency.\n",
    "- Compare your results with the spectrum from 1b). Which model order yields the \"best\" spectral envelope? What happens if the model order is too high or too low?\n",
    "- Why is it not possible to estimate the fundamental frequency based on the LP model?\n",
    "\n",
    "Useful Python functions: `pysptk.sptk.lpc`, `scipy.signal.freqz`. Check the documentation of the sptk package https://netix.dl.sourceforge.net/project/sp-tk to know which parameters are returned by the `lpc` function, and what model they correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysptk\n",
    "\n",
    "model_orders = [4, 8, 16, 50]\n",
    "lpccoeffs = [[ pysptk.sptk.lpc(iy_hamming_signal, k)[0], pysptk.sptk.lpc(iy_hamming_signal, k)[1:] ] for k in model_orders]\n",
    "\n",
    "wh = [ scipy.signal.freqz(b=lpccoeffs[k][0], a=np.concatenate((np.ones(1,), lpccoeffs[k][1])), worN=len(magn_db_iy)//2,fs=Fs) for k in range(4) ]\n",
    "\n",
    "magnitude_spectrum_db = [ 20 * np.log10(np.abs(wh[k][1])) for k in range(4) ]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for k in range(len(magnitude_spectrum_db)):\n",
    "    plt.subplot(2, 2, k + 1)\n",
    "    plt.title(f\"Spectrum of signal's AR model on order {model_orders[k]}\")\n",
    "    plt.plot(wh[k][0] / ( 2 * np.pi ), magnitude_spectrum_db[k], color='b')\n",
    "    plt.plot(wh[k][0] / ( 2 * np.pi ), magn_db_hamming[:len(magn_db_hamming)//2], color='r')\n",
    "\n",
    "plt.subplots_adjust(top=0.85, hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.exp(magnitude_spectrum_db[3] * np.log(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order 16 match the best with the spectral enveloppe (order 8 is not so bad though but we miss the pole around 1000Hz). If the order is too low, the model skips a lot of poles and if the order is too high we might have too much poles, and would have maybe even more than the original one. Zeros may appear too. \n",
    "\n",
    "It is not possible to have the fundamental frequency based on the LPC model it is supposed to only represent the shape of the spectrum, and $f_0$ is not present on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Use `scipy.signal.spectrogram` to create a spectrogram of the entire speech signal. Try to generate both wide- and narrow-band spectrograms by adjusting the window lengths and overlaps. Which characteristic traits of the speech sounds /s/, /t/, /r/ and /iy/ can you see from the spectrogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Sxx = scipy.signal.spectrogram(data, fs=Fs)\n",
    "\n",
    "plt.pcolormesh(t, f, Sxx, shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "t0, t1 = 0, len(t) // 4\n",
    "f0, f1 = len(f) // 3, len(f) // 2\n",
    "plt.pcolormesh(t[t0:t1], f[f0:f1], Sxx[f0:f1, t0:t1], shading='gouraud')\n",
    "plt.title('Caracteristic of /s/ - dense and high frequency')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "t0, t1 = len(t) // 5 ,  11 * len(t) // 24\n",
    "f0, f1 = 0, len(f)\n",
    "plt.pcolormesh(t[t0:t1], f[f0:f1], Sxx[f0:f1, t0:t1], shading='gouraud')\n",
    "plt.title('Caracteristic of /t/ - silence after the sound')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "t0, t1 = 5 * len(t) // 12, 11 * len(t) // 12\n",
    "f0, f1 = len(f) // 6, 5 * len(f) // 12\n",
    "plt.pcolormesh(t[t0:t1], f[f0:f1], Sxx[f0:f1, t0:t1], shading='gouraud')\n",
    "plt.title('Caracteristic of /r/ - looks like vowel')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "t0, t1 = 5 * len(t) // 12, len(t)\n",
    "f0, f1 = 0, len(f) // 7\n",
    "plt.pcolormesh(t[t0:t1], f[f0:f1], Sxx[f0:f1, t0:t1], shading='gouraud')\n",
    "plt.title('Caracteristic of /iy/ - dense and low frequency')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.subplots_adjust(top=0.85, hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "In this problem we look at the cepstrum and deconvolution\n",
    "\n",
    "(a) Compute and plot the real cepstrum of the vowel from problem 1a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fft_iy = np.log(np.abs(fft_iy))\n",
    "iy_cepstrum = np.fft.ifft(log_fft_iy)\n",
    "\n",
    "quef_sample = freqs_iy[1] - freqs_iy[0]\n",
    "iy_quefrency =  np.fft.fftfreq(len(iy_cepstrum), quef_sample)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(iy_quefrency[1:len(iy_quefrency) // 2], iy_cepstrum[1:len(iy_cepstrum) // 2], color='b')\n",
    "plt.title('Cepstrum of /iy/ signal')\n",
    "plt.xlabel('Quefrency (s)') \n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Use the cepstrum to compute the fundamental frequency $f_0$. Compare your results with those obtained in problem 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs, _ = signal.find_peaks(10 * np.real(iy_cepstrum[:len(iy_cepstrum) // 2]), prominence=1, height=1)\n",
    "print(f\"Estimated fundamental frequency (f0) from the cepstrum: {1 / iy_quefrency[indexs[1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is a bit different from the original one but has the same order of size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) In this subproblem you will use the cepstrum to estimate the spectral envelope\n",
    "- Use liftering to extract the part of the ceptrum that represents the spectral envelope.\n",
    "- Plot the spectral envelope as a function of frequency, and compare the result with the results from problem 1).\n",
    "\n",
    "Hint 1: Remember that the cepstrum of a real signal is symmetric, so the liftered signal must be symmetric as well.\n",
    "\n",
    "Hint 2: The FFT of a real, symmetric signal is real, but due to round-off errors small imaginary noise may occur. Use `np.real` to get to the real part of the liftered log-spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iy_lifted = iy_cepstrum * signal.hamming(len(iy_cepstrum))\n",
    "\n",
    "fft_iy_lifted = np.fft.fft(iy_lifted, n=1024)\n",
    "\n",
    "order = 16\n",
    "K, lpccoeffs = pysptk.sptk.lpc(iy_lifted, order)[0], pysptk.sptk.lpc(iy_lifted, order)[1:]\n",
    "w, h = scipy.signal.freqz(b=K, a=np.concatenate((np.ones(1,), lpccoeffs)), worN=len(iy_lifted)//2,fs=1/quef_sample)\n",
    "\n",
    "magn_spec_db = 20 * np.log10(np.abs(h))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.title(f\"Spectrum of signal's AR model on order {order} based on signal cepstrum\")\n",
    "plt.plot( w / ( 2 * np.pi ), magn_spec_db, color='b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "sig_p1",
   "language": "python",
   "name": "sig_p1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
