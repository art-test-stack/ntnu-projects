{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variational_autoencoder import VariationalAutoEncoder\n",
    "from verification_net import VerificationNet\n",
    "from stacked_mnist import StackedMNIST, DataMode\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "torch.mps.set_per_process_memory_fraction(0.)\n",
    "\n",
    "model_file = Path(\"models/vae-basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedVAE(VariationalAutoEncoder):\n",
    "    def __init__(self, latent_space_size: int = 64) -> None:\n",
    "        super().__init__(latent_space_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        nb_channels = x.shape[1]\n",
    "        mus, log_vars = [], []\n",
    "        x_hat = []\n",
    "        for channel in range(nb_channels):\n",
    "            x_channel = x[:, [channel], :, :]\n",
    "            mu, log_var = self.encoder(x_channel)\n",
    "\n",
    "            mus.append(mu.view(-1, 1, self.latent_space_size))\n",
    "            log_vars.append(log_var.view(-1, 1, self.latent_space_size))\n",
    "\n",
    "            std = torch.sqrt(torch.exp(log_var))\n",
    "            eps = torch.randn_like(std)\n",
    "\n",
    "            z = mu + eps * std\n",
    "            x_hat.append(self.decoder(z))\n",
    "\n",
    "        mus = torch.cat(mus, dim=1)\n",
    "        log_vars = torch.cat(log_vars, dim=1)\n",
    "        x_hat = torch.cat(x_hat, dim=1)\n",
    "        return (mus, log_vars), x_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = StackedVAE()\n",
    "VAE.load_state_dict(torch.load(model_file))\n",
    "\n",
    "VAE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, params):\n",
    "    x_hat, x = X\n",
    "    mu, log_var = params\n",
    "    \n",
    "    BCE = F.binary_cross_entropy(x_hat, x, reduction='mean')\n",
    "    KLD = torch.mean(- 0.5 * torch.mean(1 + log_var - mu.pow(2) - torch.exp(log_var), axis=1))\n",
    "\n",
    "    return BCE + .06 * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = DataMode.COLOR | DataMode.BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = StackedMNIST(train=True, mode=mode)\n",
    "testset = StackedMNIST(train=False, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "data = DataLoader(trainset, shuffle=True, batch_size=batch_size)\n",
    "x, _, labels = next(iter(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=trainset, shuffle=True, batch_size=2048)\n",
    "test_loader = DataLoader(dataset=testset, shuffle=True, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import tile_tv_images, tile_pil_images\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "def print_reconstructed_img(dataset, batch_size: int = 25):\n",
    "    data = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "    imgs, _, labels = next(iter(data))\n",
    "\n",
    "    _, imgs_pred = VAE(imgs.to(device))\n",
    "    \n",
    "    labels = labels.detach().numpy()\n",
    "    imgs_pil = [ ToPILImage()(img_pred.cpu()) for img_pred in imgs_pred ]\n",
    "    tile_pil_images(images=imgs_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(trainset, shuffle=True, batch_size=1000)\n",
    "imgs, _, labels = next(iter(data))\n",
    "\n",
    "_, imgs_pred = VAE(imgs.to(device))\n",
    "imgs_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_reconstructed_img(trainset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_reconstructed_img(testset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VerifNet = VerificationNet(force_learn=False, file_name='models/verification_model')\n",
    "\n",
    "data = DataLoader(trainset, shuffle=True, batch_size=10000)\n",
    "imgs, _, labels = next(iter(data))\n",
    "\n",
    "labels = labels.detach().numpy()\n",
    "_, preds = VAE(imgs.to(device))\n",
    "\n",
    "cov = VerifNet.check_class_coverage(data=imgs, tolerance=.8)\n",
    "pred, acc = VerifNet.check_predictability(data=preds, correct_labels=labels, tolerance=.8)\n",
    "print(f\"Coverage: {100*cov:.2f}%\")\n",
    "print(f\"Predictability: {100*pred:.2f}%\")\n",
    "print(f\"Accuracy: {100 * acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(testset, shuffle=True, batch_size=10000)\n",
    "imgs, _, labels = next(iter(data))\n",
    "\n",
    "labels = labels.detach().numpy()\n",
    "_, preds = VAE(imgs.to(device))\n",
    "\n",
    "cov = VerifNet.check_class_coverage(data=imgs, tolerance=.8)\n",
    "pred, acc = VerifNet.check_predictability(data=preds, correct_labels=labels, tolerance=.8)\n",
    "print(f\"Coverage: {100*cov:.2f}%\")\n",
    "print(f\"Predictability: {100*pred:.2f}%\")\n",
    "print(f\"Accuracy: {100 * acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorbar_classification(classes, mean_accuracy, std_accuracy):\n",
    "    x = classes\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x, mean_accuracy, width, yerr=std_accuracy, label='Accuracy')\n",
    "\n",
    "    ax.set_ylabel('p(x)')\n",
    "    ax.set_title('p(x)')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(testset, shuffle=True, batch_size=10000)\n",
    "imgs, _, labels = next(iter(data))\n",
    "\n",
    "labels = labels.detach().numpy()\n",
    "imgs = imgs.to(device)\n",
    "_, preds = VAE(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class_accuracies = [[] for _ in range(1000)]\n",
    "probas = []\n",
    "nb_channels = 3\n",
    "\n",
    "for x, label in tqdm(zip(imgs, labels)):\n",
    "    x = x.view(1, 3, 28, 28)\n",
    "    x_hat = []\n",
    "    for channel in range(nb_channels):\n",
    "        x_channel = x[:, [channel], :, :]\n",
    "        \n",
    "        mu, log_var = VAE.encoder(x_channel)\n",
    "        std = torch.sqrt(torch.exp(log_var))\n",
    "        eps = torch.randn_like(std.expand(nb_samples,64)).to(device)\n",
    "\n",
    "        z = mu + eps * std\n",
    "        x_hat.append(VAE.decoder(z))\n",
    "\n",
    "    x_hat = torch.cat(x_hat, dim=1)\n",
    "    \n",
    "\n",
    "    x = x.expand(nb_samples, 3, 28, 28)\n",
    "    class_accuracies[label].append((-F.binary_cross_entropy(x_hat, x)).exp().mean().cpu().detach().numpy())\n",
    "    probas.append((-F.binary_cross_entropy(x_hat, x)).exp().mean().cpu().detach().numpy())\n",
    "    \n",
    "mean_accuracy = [np.mean(acc) for acc in class_accuracies]\n",
    "std_accuracy = [np.std(acc) for acc in class_accuracies]\n",
    "\n",
    "probas = np.array(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorbar_classification(np.arange(1000), mean_accuracy=mean_accuracy, std_accuracy=std_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_anomalous(k, losses, preds, labels, is_bottom = True):\n",
    "    idx = np.argsort(losses)[:k] if is_bottom else np.flip(np.argsort(losses))[:k]\n",
    "\n",
    "    new_labels = [ \n",
    "        str(f\"p(x={labels[_id]}) = {int(losses[_id] * 1e3) / 1e3}\") for _id in idx\n",
    "        ]\n",
    "    \n",
    "    tile_tv_images(images=preds[idx], labels=new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_anomalous(15, probas, preds.permute(0, 2, 3, 1).cpu().detach().numpy(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_anomalous(15, probas, imgs.permute(0, 2, 3, 1).cpu().detach().numpy(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_anomalous(15, probas, preds.permute(0, 2, 3, 1).cpu().detach().numpy(), labels, is_bottom=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.argsort(mean_accuracy)[:16]\n",
    "is_color = preds.shape[1] == 3\n",
    "\n",
    "new_labels = [ \n",
    "    str(f\"p(x={x_value})={int(mean_accuracy[x_value] * 1e3) / 1e3}\") for x_value in x_values\n",
    "    ]\n",
    "np_imgs_predicted = preds.reshape(-1, 28, 28).cpu().detach().numpy() if not is_color else preds.permute(0,2,3,1).cpu().detach().numpy()\n",
    "\n",
    "anomalies_pred = np.array([ np_imgs_predicted[np.argwhere(labels == x_value)[:,0]][0] for x_value in x_values ])\n",
    "\n",
    "tile_tv_images(images=anomalies_pred, labels=new_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
