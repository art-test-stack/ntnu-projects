{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verification_net import VerificationNet\n",
    "from model_trainer import ModelTrainer\n",
    "from autoencoder import AutoEncoder\n",
    "\n",
    "from utils import top_anomalous, top_mean_anomalous, errorbar_classification\n",
    "\n",
    "from stacked_mnist import StackedMNIST, DataMode\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "torch.mps.set_per_process_memory_fraction(0.)\n",
    "\n",
    "trainer_file = Path(\"trainers/ae-anom.pkl\")\n",
    "model_file = Path(\"models/ae-anom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderTrainer(ModelTrainer):\n",
    "    def __init__(\n",
    "            self, \n",
    "            model, \n",
    "            loss, \n",
    "            optimizer,\n",
    "            device = torch.device(\"mps\"),\n",
    "            file_name: str | Path = model_file, \n",
    "            force_learn: bool = False\n",
    "        ) -> None:\n",
    "        super().__init__(model, loss, optimizer, device, file_name, force_learn)\n",
    "\n",
    "    def get_output_from_batch(self, batch):\n",
    "        x, _, _ = batch\n",
    "        x = x.to(self.device)\n",
    "        _, output = self.model(x)\n",
    "        return x, output\n",
    "    \n",
    "latent_space_size = 64\n",
    "mode = DataMode.MONO\n",
    "\n",
    "AE = AutoEncoder(latent_space_size=latent_space_size)\n",
    "loss = nn.MSELoss()\n",
    "opt = optim.Adam(AE.parameters(), lr=1e-5)\n",
    "\n",
    "trainset = StackedMNIST(train=True, mode=mode | DataMode.MISSING)\n",
    "testset = StackedMNIST(train=False, mode=mode)\n",
    "\n",
    "Trainer = AutoEncoderTrainer(\n",
    "        model=AE, \n",
    "        loss=loss, \n",
    "        optimizer=opt, \n",
    "        file_name=model_file,\n",
    "        force_learn=False\n",
    "    )\n",
    "\n",
    "Trainer = Trainer.load_trainer(trainer_file)\n",
    "\n",
    "plt.plot(Trainer.losses, label=\"train loss\")\n",
    "plt.plot(Trainer.val_losses, label=\"val loss\")\n",
    "\n",
    "train_set = DataLoader(trainset, shuffle=True, batch_size=2048)\n",
    "test_set = DataLoader(testset, shuffle=True, batch_size=2048)\n",
    "\n",
    "Trainer.print_reconstructed_img(testset)\n",
    "\n",
    "VerifNet = VerificationNet(file_name='models/verification_model_torch_ok_copy')\n",
    "\n",
    "Trainer.print_class_coverage_and_predictability(VerifNet, trainset)\n",
    "\n",
    "Trainer.print_class_coverage_and_predictability(VerifNet, testset)\n",
    "\n",
    "def calculate_class_accuracies(X, X_hat, labels):\n",
    "    class_accuracies = [[] for _ in range(10)]\n",
    "\n",
    "    for x, x_hat, label in zip(X, X_hat, labels):\n",
    "        class_accuracies[label].append(loss(x, x_hat))\n",
    "\n",
    "    mean_accuracy = [np.mean(acc) for acc in class_accuracies]\n",
    "    std_accuracy = [np.std(acc) for acc in class_accuracies]\n",
    "\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "data = DataLoader(testset, shuffle=True, batch_size=10000)\n",
    "imgs, _, labels = next(iter(data))\n",
    "\n",
    "labels = labels.detach().numpy()\n",
    "_, preds = Trainer.model(imgs.to(device))\n",
    "\n",
    "X = imgs.to(device)\n",
    "X_hat = preds.to(device)\n",
    "\n",
    "class_accuracies = [[] for _ in range(10)]\n",
    "losses = []\n",
    "for x, x_hat, label in zip(X, X_hat, labels):\n",
    "    class_accuracies[label].append(loss(x, x_hat).item())\n",
    "    losses.append(loss(x, x_hat).item())\n",
    "    \n",
    "mean_accuracy = [np.mean(acc) for acc in class_accuracies]\n",
    "std_accuracy = [np.std(acc) for acc in class_accuracies]\n",
    "losses = np.array(losses)\n",
    "\n",
    "errorbar_classification(np.arange(10), mean_accuracy=mean_accuracy, std_accuracy=std_accuracy)\n",
    "top_anomalous(15, losses, preds.cpu().detach().numpy().reshape(-1, 28, 28), labels)\n",
    "top_mean_anomalous(9, mean_accuracy, preds, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
