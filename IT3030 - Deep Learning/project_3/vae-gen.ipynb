{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variational_autoencoder import VariationalAutoEncoder\n",
    "from verification_net import VerificationNet\n",
    "from model_trainer import ModelTrainer\n",
    "from stacked_mnist import StackedMNIST, DataMode\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "torch.mps.set_per_process_memory_fraction(0.)\n",
    "\n",
    "trainer_file = Path(\"trainers/vae-basic.pkl\")\n",
    "model_file = Path(\"models/vae-basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoderTrainer(ModelTrainer):\n",
    "    def __init__(\n",
    "            self, \n",
    "            model, \n",
    "            loss, \n",
    "            optimizer,\n",
    "            device = torch.device(\"mps\"),\n",
    "            file_name: str | Path = model_file, \n",
    "            force_learn: bool = False\n",
    "        ) -> None:\n",
    "        super().__init__(model, loss, optimizer, device, file_name, force_learn)\n",
    "\n",
    "    def get_output_from_batch(self, batch):\n",
    "        x, _, _ = batch\n",
    "        x = x.to(self.device)\n",
    "        (mu, log_var), x_hat = self.model(x)\n",
    "        return (x_hat, x), (mu, log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = VariationalAutoEncoder(latent_space_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, params):\n",
    "    x_hat, x = X\n",
    "    mu, log_var = params\n",
    "    BCE = F.binary_cross_entropy(x_hat, x, reduction='mean')\n",
    "    KLD = torch.mean(- 0.5 * torch.mean(1 + log_var - mu.pow(2) - torch.exp(log_var), axis=1))\n",
    "\n",
    "    return BCE + .02 * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(VAE.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = VariationalAutoEncoderTrainer(\n",
    "        model=VAE, \n",
    "        loss=loss, \n",
    "        optimizer=opt, \n",
    "        file_name=model_file,\n",
    "        force_learn=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = Trainer.load_trainer(trainer_file=trainer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(trainer_file.__str__(), 'rb') as inp:\n",
    "#     Trainer = pickle.load(inp)\n",
    "\n",
    "# Trainer.force_relearn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = DataMode.MONO | DataMode.BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = StackedMNIST(train=True, mode=mode)\n",
    "testset = StackedMNIST(train=False, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer.print_reconstructed_img(trainset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer.optimizer = optim.Adam(VAE.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer.loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer.train(\n",
    "        trainset=trainset, \n",
    "        valset=testset, \n",
    "        epochs=1000, \n",
    "        batch_size=2048\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Trainer.losses, label=\"train loss\")\n",
    "plt.plot(Trainer.val_losses, label=\"val loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(trainer_file, 'wb') as outp:\n",
    "#     pickle.dump(Trainer, outp, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=trainset, shuffle=True, batch_size=2048)\n",
    "test_loader = DataLoader(dataset=testset, shuffle=True, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10_000\n",
    "data = DataLoader(trainset, shuffle=True, batch_size=batch_size)\n",
    "imgs, _, labels = next(iter(data))\n",
    "\n",
    "(mu, log_var), imgs_pred = VAE(imgs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_mean = mu.mean(axis=0)\n",
    "mu_std = mu.std(axis=0)\n",
    "\n",
    "\n",
    "log_var_mean = log_var.mean(axis=0)\n",
    "log_var_std = log_var.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_noise = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_noised = torch.randn(size=(batch_noise, 64)).to(device)\n",
    "log_var_noise = torch.randn(size=(batch_noise, 64)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_noise(noise, mean, std):\n",
    "    noise_scaled = (noise - noise.mean()) / noise.std()\n",
    "    return noise_scaled * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = torch.sqrt(torch.exp(log_var_noise))\n",
    "eps = torch.randn_like(std)\n",
    "\n",
    "z = mu_noised + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_imgs = VAE.decoder(z)\n",
    "imgs_to_plot = gen_imgs[:16].cpu().detach().numpy().reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import tile_tv_images\n",
    "tile_tv_images(images=imgs_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VerifNet = VerificationNet(force_learn=False, file_name='models/verification_model_torch_ok_copy')\n",
    "\n",
    "cov = VerifNet.check_class_coverage(data=gen_imgs, tolerance=.8)\n",
    "pred, _ = VerifNet.check_predictability(data=gen_imgs, tolerance=.8)\n",
    "print(f\"Coverage: {100*cov:.2f}%\")\n",
    "print(f\"Predictability: {100*pred:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, beliefs = VerifNet.predict(data=gen_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.flip(np.argsort(beliefs))[:k]\n",
    "\n",
    "best_imgs = gen_imgs.cpu().detach().numpy().reshape(-1, 28, 28)[idx]\n",
    "labels_best_imgs = preds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tv_images(images=best_imgs, labels=labels_best_imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
