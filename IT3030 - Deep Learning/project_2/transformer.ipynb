{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "\n",
    "from transformer import Transformer\n",
    "from preprocessing import *\n",
    "from utils import *\n",
    "from features import *\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.set_per_process_memory_fraction(0.)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('consumption_and_temperatures.csv')\n",
    "raw_data['timestamp'] = pd.to_datetime(raw_data['timestamp'])\n",
    "\n",
    "seq_len = 48\n",
    "scale_output = True\n",
    "target_column = 'NO1_consumption'\n",
    "\n",
    "features_to_add = [\n",
    "    (   \n",
    "        pick_location_data,\n",
    "        { 'loc': [1] }\n",
    "    ),\n",
    "    (\n",
    "        add_season_columns, \n",
    "        {}\n",
    "    ),\n",
    "    (\n",
    "        shift_data, \n",
    "        {   \n",
    "            \"shift_min\": 24,\n",
    "            \"shift_max\": 24,\n",
    "            \"column_to_shift\": \"NO1_consumption\",\n",
    "            \"new_column_name\": \"consum\"\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        add_hour_columns,\n",
    "        {}\n",
    "    )\n",
    "]\n",
    "\n",
    "forecast_len=24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test), (scalerInputMethod, scalerOutputMethod), df_target = general_preprocessing(\n",
    "        raw_data, \n",
    "        features_to_add=features_to_add,\n",
    "        seq_len=seq_len,\n",
    "        forecast_len=24,\n",
    "        scale_output=scale_output\n",
    "    )\n",
    "\n",
    "model = Transformer(input_size=X_train.shape[2])\n",
    "model.to(device)\n",
    "\n",
    "# path = \"Transformer-2024-03-20-loss-0.035382744\"\n",
    "# path = \"models/\" + path\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model.to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs=100\n",
    "\n",
    "loss_func = nn.MSELoss()# .to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model, losses, val_loss, opt = fit(\n",
    "    model, \n",
    "    train_set=(X_train, y_train),\n",
    "    val_set=(X_val, y_val),\n",
    "    opt=opt,\n",
    "    loss_func=loss_func,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    batch_size=30\n",
    ")\n",
    "\n",
    "path = f'models/Transformer-{str(datetime.now().date())}-loss-{str(losses[len(losses)-1])}'\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "plt.plot(losses, label=\"train loss\")\n",
    "plt.plot(val_loss, label=\"val loss\")\n",
    "plt.legend()\n",
    "\n",
    "y_test, y_pred = predict(model, scalerOutputMethod, (X_test, y_test))\n",
    "plot_error_by_hour_for_test_set(y_test, y_pred, start_hour=df_target['timestamp'].dt.hour.iloc[seq_len-1])\n",
    "\n",
    "for k in range(5):\n",
    "    make_forecast(y_pred=y_pred, df_target=df_target, seq_len=seq_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsolar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
