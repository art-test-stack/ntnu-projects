{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from lstm import LSTM\n",
    "from preprocessing import *\n",
    "from utils import *\n",
    "from features import *\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.set_per_process_memory_fraction(0.)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('consumption_and_temperatures.csv')\n",
    "raw_data['timestamp'] = pd.to_datetime(raw_data['timestamp'])\n",
    "\n",
    "seq_len = 72\n",
    "scale_output=True\n",
    "target_column = 'NO1_consumption'\n",
    "\n",
    "features_to_add = [\n",
    "    (   \n",
    "        pick_location_data,\n",
    "        { 'loc': [1] }\n",
    "    ),\n",
    "    (\n",
    "        add_season_columns, \n",
    "        {}\n",
    "    ),\n",
    "    (\n",
    "        shift_data, \n",
    "        {\n",
    "            \"shift_max\": 10,\n",
    "            \"column_to_shift\": \"NO1_temperature\",\n",
    "            \"new_column_name\": \"temp\"\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        add_hour_columns,\n",
    "        {}\n",
    "    ),\n",
    "    (\n",
    "        previous_y,\n",
    "        {'target': target_column}\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test), (scalerInputMethod, scalerOutputMethod), df_target = general_preprocessing(\n",
    "        raw_data, \n",
    "        features_to_add=features_to_add,\n",
    "        seq_len=seq_len,\n",
    "        scale_output=scale_output\n",
    "    )\n",
    "\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 11\n",
    "num_layers = 3\n",
    "\n",
    "model = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "model.to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs=100\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "path2 = \"LSTM-prev-y-2024-03-20-loss-0.04269014\"\n",
    "path2 = \"models/\" + path2\n",
    "model.load_state_dict(torch.load(path2))\n",
    "model.to(device)\n",
    "\n",
    "model, losses, val_loss, opt = fit(\n",
    "    model, \n",
    "    train_set=(X_train, y_train),\n",
    "    val_set=(X_val, y_val),\n",
    "    opt=opt,\n",
    "    loss_func=loss_func,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "# path = f'models/LSTM-prev-y-{str(datetime.now().date())}-loss-{str(losses[len(losses)-1])}'\n",
    "# torch.save(model.state_dict(), path)\n",
    "\n",
    "plt.plot(losses, label=\"train loss\")\n",
    "plt.plot(val_loss, label=\"val loss\")\n",
    "plt.legend()\n",
    "\n",
    "y_test, y_pred = predict(model, scalerOutputMethod, (X_test, y_test))\n",
    "plot_error_by_hour_for_test_set(y_test, y_pred, start_hour=df_target['timestamp'].dt.hour.iloc[seq_len-1])\n",
    "for k in range(5):\n",
    "    make_forecast_replace_previous_y(model, scalerOutputMethod, (X_test, y_test), seq_len=seq_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsolar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
