{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e01b6db",
   "metadata": {},
   "source": [
    "# TTT4185 Machine learning for Speech technology\n",
    "\n",
    "## Computer assigment 3a: Classification using Deep Neural Networks\n",
    "\n",
    "This assignment assumes that the student has reviewed the material on deep neural networks.\n",
    "\n",
    "In this assignment we will use the high level `Keras` framework together with `Tensorflow` to perform some deep learning experiments.\n",
    "\n",
    "We will be using a small database of phonemes, where each phoneme is represented by the four first formant positions (\"F1\"-\"F4\") and their corresponding bandwidths (\"B1\"-\"B4\"). All numbers are in kHz. In addition, the speaker ID and the gender of the speaker are given for each phoneme.\n",
    "\n",
    "The first few cells of this notebook contain example code to load and extract data, setup a simple network and train a deep neural network for classification. \n",
    "\n",
    "Note that we do not have a test dataset, but only training and validation sets. We do some experiments on the training set and observe the effect on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41929a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV files \n",
    "rawtrain = pd.read_csv(\"Train.csv\")\n",
    "rawvalid = pd.read_csv(\"Validation.csv\")\n",
    "\n",
    "# Take a peek at the raw data\n",
    "rawtrain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be classifying three different vowels. Extract the training and validation data\n",
    "phonemes = [\"ae\", \"ey\", \"ux\"]\n",
    "train = rawtrain[rawtrain[\"Phoneme\"].isin(phonemes)]\n",
    "valid = rawvalid[rawvalid[\"Phoneme\"].isin(phonemes)]\n",
    "trainlabels = [phonemes.index(ph) for ph in train[\"Phoneme\"]]\n",
    "validlabels = [phonemes.index(ph) for ph in valid[\"Phoneme\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e18c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to use\n",
    "features = [\"F1\",\"F2\"]\n",
    "\n",
    "# Extract features\n",
    "x_train_raw = train[features]\n",
    "x_valid_raw = valid[features]\n",
    "\n",
    "# Normalize to zero mean\n",
    "x_mean = np.mean(x_train_raw)\n",
    "x_std = np.std(x_train_raw)\n",
    "x_train = (x_train_raw - x_mean) / x_std\n",
    "x_valid = (x_valid_raw - x_mean) / x_std\n",
    "\n",
    "# Fix labels. The \"to_categorical\" call maps integer labels {n}\n",
    "# to a vector of length N (number of labels) with a one in position n\n",
    "y_train = keras.utils.to_categorical(trainlabels, len(phonemes))\n",
    "y_valid = keras.utils.to_categorical(validlabels, len(phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with a single hidden layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu, input_dim=x_train.shape[1]),\n",
    "    keras.layers.Dense(len(phonemes), activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=1000, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training results\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd0e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b55d7",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "Increase the number of features to include \"F3\" and \"F4\" and rerun the experiments. Try also adding the bandwidths (\"B1\"-\"B4\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we add \"F3\" and \"F4\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"F1\",\"F2\",\"F3\",\"F4\"]\n",
    "\n",
    "# Extract features\n",
    "x_train_raw = train[features]\n",
    "x_valid_raw = valid[features]\n",
    "\n",
    "# Normalize to zero mean\n",
    "x_mean = np.mean(x_train_raw)\n",
    "x_std = np.std(x_train_raw)\n",
    "x_train = (x_train_raw - x_mean) / x_std\n",
    "x_valid = (x_valid_raw - x_mean) / x_std\n",
    "\n",
    "# Fix labels. The \"to_categorical\" call maps integer labels {n}\n",
    "# to a vector of length N (number of labels) with a one in position n\n",
    "y_train = keras.utils.to_categorical(trainlabels, len(phonemes))\n",
    "y_valid = keras.utils.to_categorical(validlabels, len(phonemes))\n",
    "\n",
    "# Create a model with a single hidden layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu, input_dim=x_train.shape[1]),\n",
    "    keras.layers.Dense(len(phonemes), activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=1000, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training results\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44273d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version looks a bit overfitting (the loss which increase from 500 epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we add the bandwidths \"B1\"-\"B4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84365f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"F1\",\"F2\",\"F3\",\"F4\",\"B1\",\"B2\",\"B3\",\"B4\"]\n",
    "\n",
    "# Extract features\n",
    "x_train_raw = train[features]\n",
    "x_valid_raw = valid[features]\n",
    "\n",
    "# Normalize to zero mean\n",
    "x_mean = np.mean(x_train_raw)\n",
    "x_std = np.std(x_train_raw)\n",
    "x_train = (x_train_raw - x_mean) / x_std\n",
    "x_valid = (x_valid_raw - x_mean) / x_std\n",
    "\n",
    "# Fix labels. The \"to_categorical\" call maps integer labels {n}\n",
    "# to a vector of length N (number of labels) with a one in position n\n",
    "y_train = keras.utils.to_categorical(trainlabels, len(phonemes))\n",
    "y_valid = keras.utils.to_categorical(validlabels, len(phonemes))\n",
    "\n",
    "# Create a model with a single hidden layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu, input_dim=x_train.shape[1]),\n",
    "    keras.layers.Dense(len(phonemes), activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=1000, batch_size=32, verbose=True)\n",
    "\n",
    "# Visualize the training results\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Validation model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look like overfitting but the model doesn't look learning very quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424de4b7",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "Change the number of nodes in the hidden layer and see how the results change. Try using dropout, and observe the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the number of nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"F1\",\"F2\",\"F3\",\"F4\",\"B1\",\"B2\",\"B3\",\"B4\"]\n",
    "\n",
    "# Extract features\n",
    "x_train_raw = train[features]\n",
    "x_valid_raw = valid[features]\n",
    "\n",
    "# Normalize to zero mean\n",
    "x_mean = np.mean(x_train_raw)\n",
    "x_std = np.std(x_train_raw)\n",
    "x_train = (x_train_raw - x_mean) / x_std\n",
    "x_valid = (x_valid_raw - x_mean) / x_std\n",
    "\n",
    "# Fix labels. The \"to_categorical\" call maps integer labels {n}\n",
    "# to a vector of length N (number of labels) with a one in position n\n",
    "y_train = keras.utils.to_categorical(trainlabels, len(phonemes))\n",
    "y_valid = keras.utils.to_categorical(validlabels, len(phonemes))\n",
    "\n",
    "# Create a model with a single hidden layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_dim=x_train.shape[1]),\n",
    "    keras.layers.Dense(len(phonemes), activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=1000, batch_size=32, verbose=True)\n",
    "\n",
    "# Visualize the training results\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Validation model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9490fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"F1\",\"F2\",\"F3\",\"F4\",\"B1\",\"B2\",\"B3\",\"B4\"]\n",
    "\n",
    "# Extract features\n",
    "x_train_raw = train[features]\n",
    "x_valid_raw = valid[features]\n",
    "\n",
    "# Normalize to zero mean\n",
    "x_mean = np.mean(x_train_raw)\n",
    "x_std = np.std(x_train_raw)\n",
    "x_train = (x_train_raw - x_mean) / x_std\n",
    "x_valid = (x_valid_raw - x_mean) / x_std\n",
    "\n",
    "# Fix labels. The \"to_categorical\" call maps integer labels {n}\n",
    "# to a vector of length N (number of labels) with a one in position n\n",
    "y_train = keras.utils.to_categorical(trainlabels, len(phonemes))\n",
    "y_valid = keras.utils.to_categorical(validlabels, len(phonemes))\n",
    "\n",
    "# Create a model with a single hidden layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(258, activation=tf.nn.relu, input_dim=x_train.shape[1]),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(phonemes), activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=1000, batch_size=32, verbose=True)\n",
    "\n",
    "# Visualize the training results\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Validation model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"F1\",\"F2\",\"F3\",\"F4\",\"B1\",\"B2\",\"B3\",\"B4\"]\n",
    "\n",
    "# Extract features\n",
    "x_train_raw = train[features]\n",
    "x_valid_raw = valid[features]\n",
    "\n",
    "# Normalize to zero mean\n",
    "x_mean = np.mean(x_train_raw)\n",
    "x_std = np.std(x_train_raw)\n",
    "x_train = (x_train_raw - x_mean) / x_std\n",
    "x_valid = (x_valid_raw - x_mean) / x_std\n",
    "\n",
    "# Fix labels. The \"to_categorical\" call maps integer labels {n}\n",
    "# to a vector of length N (number of labels) with a one in position n\n",
    "y_train = keras.utils.to_categorical(trainlabels, len(phonemes))\n",
    "y_valid = keras.utils.to_categorical(validlabels, len(phonemes))\n",
    "\n",
    "# Create a model with a single hidden layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_dim=x_train.shape[1]),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(phonemes), activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=1000, batch_size=32, verbose=True)\n",
    "\n",
    "# Visualize the training results\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Validation model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation loss decreases when we add both and the validation accuracy is slyghtly higher.\n",
    "\n",
    "We can notice that it is our best result until now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97afb4a8",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "Add multiple layers to the network and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33711985",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"F1\",\"F2\",\"F3\",\"F4\",\"B1\",\"B2\",\"B3\",\"B4\"]\n",
    "\n",
    "# Extract features\n",
    "x_train_raw = train[features]\n",
    "x_valid_raw = valid[features]\n",
    "\n",
    "# Normalize to zero mean\n",
    "x_mean = np.mean(x_train_raw)\n",
    "x_std = np.std(x_train_raw)\n",
    "x_train = (x_train_raw - x_mean) / x_std\n",
    "x_valid = (x_valid_raw - x_mean) / x_std\n",
    "\n",
    "# Fix labels. The \"to_categorical\" call maps integer labels {n}\n",
    "# to a vector of length N (number of labels) with a one in position n\n",
    "y_train = keras.utils.to_categorical(trainlabels, len(phonemes))\n",
    "y_valid = keras.utils.to_categorical(validlabels, len(phonemes))\n",
    "\n",
    "# Create a model with a single hidden layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu, input_dim=x_train.shape[1]),\n",
    "    # keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    # keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(phonemes), activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=1000, batch_size=32, verbose=True)\n",
    "\n",
    "# Visualize the training results\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Validation model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get over-fitting: the validation loss increases while the training loss decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25662cdd",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "Use the data to predict the gender of the speaker. Try including the format bandwidths as features as well (\"B1\"-\"B4\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4345da",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = [\"ae\", \"ey\", \"ux\"]\n",
    "train = rawtrain[rawtrain[\"Phoneme\"].isin(phonemes)]\n",
    "valid = rawvalid[rawvalid[\"Phoneme\"].isin(phonemes)]\n",
    "trainlabels = [phonemes.index(ph) for ph in train[\"Phoneme\"]]\n",
    "validlabels = [phonemes.index(ph) for ph in valid[\"Phoneme\"]]\n",
    "\n",
    "train['Gender'] = train['Gender'].map({'M': 0, 'F': 1})\n",
    "valid['Gender'] = valid['Gender'].map({'M': 0, 'F': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3445d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"F1\",\"F2\",\"F3\",\"F4\",\"B1\",\"B2\",\"B3\",\"B4\"]\n",
    "\n",
    "# Extract features\n",
    "x_train_raw = train[features]\n",
    "x_valid_raw = valid[features]\n",
    "\n",
    "# Normalize to zero mean\n",
    "x_mean = np.mean(x_train_raw)\n",
    "x_std = np.std(x_train_raw)\n",
    "x_train = x_train_raw - x_mean\n",
    "x_valid = x_valid_raw - x_mean\n",
    "\n",
    "# Fix labels. The \"to_categorical\" call maps integer labels {n}\n",
    "# to a vector of length N (number of labels) with a one in position n\n",
    "# y_train = keras.utils.to_categorical(trainlabels, len(phonemes))\n",
    "# y_valid = keras.utils.to_categorical(validlabels, len(phonemes))\n",
    "\n",
    "y_train = train['Gender'].values\n",
    "y_valid = valid['Gender'].values\n",
    "\n",
    "\n",
    "# Create a model with a single hidden layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu, input_dim=x_train.shape[1]),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    # keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=1000, batch_size=32, verbose=True)\n",
    "\n",
    "# Visualize the training results\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Validation model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is not bad. However, we can see that the validation slightly increases. That could mean that the model is starting to overfit. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signalp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
